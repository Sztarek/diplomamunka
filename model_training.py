# -*- coding: utf-8 -*-
"""model_training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Uh6FjUN9NgjBPHTrBR68-ZRfABnpv88z

# Peak Detection Model Training

This notebook implements multiple deep learning models for peak detection in time series data, with hyperparameter optimization using Optuna.
"""

# Install required packages if needed

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
# from sklearn.metrics import f1_score
import os
import pickle
import tensorflow as tf
from keras.models import Sequential, Model
from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, LSTM, Input, Reshape
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.optimizers import Adam
import optuna
from optuna.integration import TFKerasPruningCallback

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'



# Check TensorFlow device information
print("TensorFlow version:", tf.__version__)
print("\nAvailable devices:")
for device in tf.config.list_physical_devices():
    print(device)
print("\nGPU Available:", tf.test.is_built_with_cuda())
print("GPU Device Name:", tf.test.gpu_device_name())

# Optional: Set memory growth for GPU
try:
    tf.config.set_logical_device_configuration(
        gpus[0],
        [tf.config.LogicalDeviceConfiguration(memory_limit=4024)])
    logical_gpus = tf.config.list_logical_devices('GPU')
    print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
except:
    print("\nNo GPU devices found")

"""## Data Loading and Preprocessing"""

def load_and_preprocess_data(data_folder = 'dataset/'):
    all_files = os.listdir(data_folder)
    dfs = []

    for file in all_files:
        with open(os.path.join(data_folder, file), 'rb') as f:
            df = pickle.load(f)
            df['is_peak'] = 0
            idx_list = []

            for col in df.columns:
                if col.startswith('arps'):
                    # Check if there are any values greater than 0 before accessing the index
                    if (df[col] > 0).any():
                        idx_list.append(df[df[col] > 0].index[0])

            for idx in idx_list:
                df.loc[idx, 'is_peak'] = 1
            dfs.append(df)

    data_X = []
    data_Y = []
    max_length = max(len(df) for df in dfs)

    for df in dfs:
        starting_date = df['BOE'].index[0].date()
        date_index = pd.date_range(start=starting_date, periods=max_length, freq='MS')
        df = df.reindex(date_index)
        df = df[['BOE', 'is_peak']]
        df.ffill(inplace=True)

        # Normalize the entire time series
        normalized_boe = (df['BOE'].values - df['BOE'].mean()) / df['BOE'].std()
        
        # Create 20-length segments with stride of 15
        window_size = 20
        stride = 15
        
        # First pass: collect all segments and their peak status
        segments = []
        peak_labels = []
        has_peak_in_segment = []
        
        for i in range(0, len(normalized_boe) - window_size + 1, stride):
            segment = normalized_boe[i:i + window_size]
            segment_peak_labels = df['is_peak'].values[i:i + window_size]
            segments.append(segment)
            peak_labels.append(segment_peak_labels)
            has_peak_in_segment.append(any(segment_peak_labels))
        
        # Convert to numpy arrays for easier manipulation
        segments = np.array(segments)
        peak_labels = np.array(peak_labels)
        has_peak_in_segment = np.array(has_peak_in_segment)
        
        # Get indices of segments with and without peaks
        peak_indices = np.where(has_peak_in_segment)[0]
        non_peak_indices = np.where(~has_peak_in_segment)[0]
        
        # Calculate how many non-peak segments we need (2x the number of peak segments)
        num_peak_segments = len(peak_indices)
        num_non_peak_segments = min(2 * num_peak_segments, len(non_peak_indices))
        
        # Randomly select non-peak segments
        selected_non_peak_indices = np.random.choice(non_peak_indices, num_non_peak_segments, replace=False)
        
        # Combine selected segments
        selected_indices = np.concatenate([peak_indices, selected_non_peak_indices])
        
        # Add selected segments to the main dataset
        data_X.extend(segments[selected_indices])
        data_Y.extend(peak_labels[selected_indices])

    # Convert to numpy arrays
    X = np.array(data_X)
    y = np.array(data_Y)

    # Shuffle the dataset
    shuffle_indices = np.random.permutation(len(X))
    X = X[shuffle_indices]
    y = y[shuffle_indices]


    return X, y

"""## Model Architectures"""

class ReshapeF1Score(tf.keras.metrics.F1Score):
    def __init__(self, name='f1_score', **kwargs):
        super().__init__(name=name, **kwargs)
    
    def update_state(self, y_true, y_pred, sample_weight=None):
        # Remove extra dimension from y_pred if it exists
        if len(y_pred.shape) == 3:
            y_pred = tf.squeeze(y_pred, axis=-1)
        
        # Reshape both inputs to 2D
        y_true = tf.reshape(y_true, [-1, 1])
        y_pred = tf.reshape(y_pred, [-1, 1])
        
        super().update_state(y_true, y_pred, sample_weight)

def create_cnn_model(input_shape, trial=None):
    if trial:
        if isinstance(trial, dict):  # If trial is actually best_params
            n_filters1 = trial['n_filters1']
            n_filters2 = trial['n_filters2']
            kernel_size = trial['kernel_size']
            dense_units = trial['dense_units']
            dropout_rate = trial['dropout_rate']
            learning_rate = trial['learning_rate']
        else:  # If trial is an Optuna trial object
            n_filters1 = trial.suggest_int('n_filters1', 4, 32)
            n_filters2 = trial.suggest_int('n_filters2', 4, 32)
            kernel_size = trial.suggest_int('kernel_size', 3, 3)
            dense_units = trial.suggest_int('dense_units', 4, 128)
            dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)
            learning_rate = trial.suggest_float('learning_rate', 1e-6, 1e-2, log=True)
    else:
        n_filters1, n_filters2 = 8, 16
        dense_units = 256
        dropout_rate = 0.5
        learning_rate = 0.001
        kernel_size = 3

    model = Sequential([
        Conv1D(n_filters1, kernel_size, padding='same', activation='relu', input_shape=input_shape),
        BatchNormalization(),
        MaxPooling1D(2),

        Conv1D(n_filters2, kernel_size, padding='same', activation='relu'),
        BatchNormalization(),
        MaxPooling1D(2),

        Flatten(),
        Dense(dense_units, activation='relu'),
        BatchNormalization(),
        Dropout(dropout_rate),
        Dense(input_shape[0], activation='sigmoid')
    ])

    optimizer = Adam(learning_rate=learning_rate, clipnorm=1.0)
    model.compile(
        optimizer=optimizer,
        loss='binary_crossentropy',
        metrics=['f1_score']
    )
    return model

def create_lstm_model(input_shape, trial=None):
    if trial:
        if isinstance(trial, dict):  # If trial is actually best_params
            lstm_units1 = trial['lstm_units1']
            lstm_units2 = trial['lstm_units2']
            dense_units = trial['dense_units']
            dropout_rate = trial['dropout_rate']
            learning_rate = trial['learning_rate']
        else:  # If trial is an Optuna trial object
            lstm_units1 = trial.suggest_int('lstm_units1', 32, 64)
            lstm_units2 = trial.suggest_int('lstm_units2', 32, 64)
            dense_units = trial.suggest_int('dense_units', 32, 128)
            dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)
            learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)
    else:
        lstm_units1, lstm_units2 = 128, 64
        dense_units = 256
        dropout_rate = 0.5
        learning_rate = 0.001

    model = Sequential([
        LSTM(lstm_units1, return_sequences=True, input_shape=input_shape),
        BatchNormalization(),
        Dropout(dropout_rate),

        LSTM(lstm_units2),
        BatchNormalization(),
        Dropout(dropout_rate),

        Dense(dense_units, activation='relu'),
        BatchNormalization(),
        Dropout(dropout_rate),
        Dense(input_shape[0], activation='sigmoid')
    ])

    optimizer = Adam(learning_rate=learning_rate, clipnorm=1.0)
    model.compile(
        optimizer=optimizer,
        loss='binary_crossentropy',
        metrics=['f1_score']
    )
    return model

def create_autoencoder_model(input_shape, trial=None):
    if trial:
        if isinstance(trial, dict):  # If trial is actually best_params
            encoding_dim = trial['encoding_dim']
            dense_units = trial['dense_units']
            dropout_rate = trial['dropout_rate']
        else:  # If trial is an Optuna trial object
            encoding_dim = trial.suggest_int('encoding_dim', 8, 32)
            dense_units = trial.suggest_int('dense_units', 8, 32)
            dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)
    else:
        encoding_dim = 128
        dense_units = 256
        dropout_rate = 0.5

    # Input layer
    input_layer = Input(shape=input_shape)
    
    # Flatten the input if it's 3D
    x = Flatten()(input_layer)
    
    # Encoder
    encoded = Dense(encoding_dim, activation='relu')(x)
    encoded = BatchNormalization()(encoded)
    encoded = Dropout(dropout_rate)(encoded)

    # Decoder
    decoded = Dense(dense_units, activation='relu')(encoded)
    decoded = BatchNormalization()(decoded)
    decoded = Dropout(dropout_rate)(decoded)
    decoded = Dense(input_shape[0] * input_shape[1], activation='sigmoid')(decoded)
    decoded = Reshape(input_shape, name='mse')(decoded)

    # Peak detection head
    peak_output = Dense(input_shape[0] * input_shape[1], activation='sigmoid')(encoded)
    peak_output = Reshape(input_shape, name='f1_score')(peak_output)

    # Create model with two outputs
    model = Model(inputs=input_layer, outputs=[decoded, peak_output])

    model.compile(
        optimizer=Adam(learning_rate=0.001),
        loss=['mse', 'binary_crossentropy'],
        metrics={'mse': ['mse'], 'f1_score': [ReshapeF1Score()]}
    )
    return model

"""## Hyperparameter Optimization"""

def objective(trial):
    # Load and preprocess data
    X, y = load_and_preprocess_data()

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    split_index = int(0.5 * len(X_test))
    val_X, val_Y = X_test[split_index:], y_test[split_index:]
    test_X, test_Y = X_test[:split_index], y_test[:split_index]

    # Model selection
    model_type = trial.suggest_categorical('model_type', ['lstm'])

    if model_type == 'cnn':
        model = create_cnn_model((X_train.shape[1], 1), trial)
    elif model_type == 'lstm':
        model = create_lstm_model((X_train.shape[1], 1), trial)
    else:
        model = create_autoencoder_model((X_train.shape[1], 1), trial)

    # Training
    callbacks = [
        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
        TFKerasPruningCallback(trial, 'val_loss')
    ]

    try:
        if model_type == 'autoencoder':
            # For autoencoder, we need to provide both reconstruction and peak detection targets
            train_targets = [X_train, y_train]
            val_targets = [val_X, val_Y]
            test_targets = [test_X, test_Y]
            
            history = model.fit(
                X_train,
                train_targets,
                epochs=10,
                batch_size=8,
                validation_data=(val_X, val_targets),
                callbacks=callbacks,
                verbose=0
            )
            
            # Manual evaluation
            print("\nManual Evaluation:")
            predictions = model.predict(test_X)
            reconstruction_pred = predictions[0]
            peak_pred = predictions[1]
        
            
            # Calculate peak detection metrics
            peak_pred = tf.cast(peak_pred > 0.5, tf.float32)
            peak_pred = tf.reshape(peak_pred, [-1])
            test_Y_flat = tf.reshape(test_Y, [-1])
            
            # Calculate F1 score manually
            true_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(test_Y_flat, 1), tf.equal(peak_pred, 1)), tf.float32))
            false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(test_Y_flat, 0), tf.equal(peak_pred, 1)), tf.float32))
            false_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(test_Y_flat, 1), tf.equal(peak_pred, 0)), tf.float32))
            
            precision = true_positives / (true_positives + false_positives + tf.keras.backend.epsilon())
            recall = true_positives / (true_positives + false_negatives + tf.keras.backend.epsilon())
            f1 = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())
            
            test_acc = f1
        else:
            history = model.fit(
                X_train,
                y_train,
                epochs=10,
                batch_size=8,
                validation_data=(val_X, val_Y),
                callbacks=callbacks,
                verbose=0
            )
            test_results = model.evaluate(test_X, test_Y, batch_size=8, verbose=0)
            test_acc = np.mean(test_results[1])

        # Check for NaN values in evaluation
        if np.isnan(test_acc):
            return float('-inf')

        return test_acc
    except Exception as e:
        print(f"Trial failed with error: {str(e)}")
        return float('-inf')

"""## Model Training"""

def train_models():
    # Create study for hyperparameter optimization
    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())
    study.optimize(objective, n_trials=15)

    # Get best parameters
    best_params = study.best_params
    best_value = study.best_value
    print(f"Best acc score: {best_value:.4f}")
    print("Best parameters:", best_params)

    # Train final model with best parameters
    X, y = load_and_preprocess_data()
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    print(X_train.shape)
    print(y_train.shape)

    model_type = best_params['model_type']
    print(best_params)
    if model_type == 'cnn':
        model = create_cnn_model((X_train.shape[1], 1), best_params)
    elif model_type == 'autoencoder':
        model = create_autoencoder_model((X_train.shape[1], 1), best_params)
    else:
        model = create_lstm_model((X_train.shape[1], 1), best_params)

    # Train final model
    callbacks = [
        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
        ModelCheckpoint(f'best_{model_type}_model.keras', monitor='val_loss', save_best_only=True)
    ]

    history = model.fit(
        X_train,
        y_train,
        epochs=10,
        batch_size=8,
        validation_split=0.2,
        callbacks=callbacks
    )

    # Evaluate final model
    test_loss, test_acc = model.evaluate(X_test, y_test, batch_size=8)
    print(f"\nFinal Model Results:")
    print(f"Test accuracy: {test_acc:.4f}")

    return model, history

def train_autoencoder(X_train, y_train, val_X, val_Y, test_X, test_Y):
    # Reshape the data to match the expected input shape
    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
    val_X = val_X.reshape(val_X.shape[0], val_X.shape[1], 1)
    test_X = test_X.reshape(test_X.shape[0], test_X.shape[1], 1)
    
    # Reshape the target data to match the expected output shape
    y_train = y_train.reshape(y_train.shape[0], y_train.shape[1], 1)
    val_Y = val_Y.reshape(val_Y.shape[0], val_Y.shape[1], 1)
    test_Y = test_Y.reshape(test_Y.shape[0], test_Y.shape[1], 1)
    
    # Create and compile the model
    model = create_autoencoder_model((X_train.shape[1], 1))
    
    # Prepare the data for training
    train_targets = [X_train, y_train]  # [reconstruction_target, peak_detection_target]
    val_targets = [val_X, val_Y]        # [reconstruction_target, peak_detection_target]
    test_targets = [test_X, test_Y]     # [reconstruction_target, peak_detection_target]
    
    # Train the model
    history = model.fit(
        X_train,  # Input data
        train_targets,  # Targets for both outputs
        epochs=10,
        batch_size=8,
        validation_data=(val_X, val_targets),
        callbacks=[
            EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
        ]
    )
    
    # Evaluate the model
    test_loss = model.evaluate(test_X, test_targets)
    print(f"Test loss: {test_loss}")
    
    return model, history
"""## Run Training"""

# Load and preprocess data
model, history = train_models()

"""## Plot Training History"""

import matplotlib.pyplot as plt

def plot_training_history(history):
    plt.figure(figsize=(12, 4))

    # Plot loss
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    # Plot accuracy
    plt.subplot(1, 2, 2)
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Model Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('f1_score')
    plt.legend()

    plt.tight_layout()
    plt.show()

plot_training_history(history)